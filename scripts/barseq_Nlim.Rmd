---
title: "Barseq QC"
author: "Siyu Sun"
date: "`r Sys.Date()`"
output: html_document
---

### load packages

```{r,cache=TRUE}
library(ggplot2)
library(reshape2)
library(ggrepel)
```

### read in index file with pre-known information (self made-varied depends on experiment setup)

```{r,cache=TRUE}
index <- read.csv("../data/GeneInter_N_lim.csv")
rownames(index)<-index$SampleIndex
head(index)
```

###Counts tables, melted

Here we make a list of data.frames, where each data.frame is just the counts table of a different Barnone run, with each a different mismatch allowed.

```{r,cache=TRUE}
allFileNames <- list.files(path="../data/",pattern=".*counts.txt",full.names=T)
rawCountsList <- list()
for (fz in allFileNames) {
  numberMismatches <- sub(".*(\\dMM).*","\\1",fz)
  rawCountsList[[numberMismatches]] <- read.table(fz,header=T)
}
rawCountsList[[1]][1:5,1:5]

#Below, we melt the data into a tidy long data.frame:
datar <- list()
for (MM in names(rawCountsList)) {
  mcounts <- melt(rawCountsList[[MM]], id.vars="Strain", value.name="Counts")
  mcounts[,ncol(mcounts)+1:2] <- colsplit(mcounts$variable,"_", c("SampleNum","Tag"))
 #aggregate counts in each sample collection -- from same set of genomic DNA
  sampleTotalCounts <- aggregate(Counts~variable,data=mcounts,sum)
  rownames(sampleTotalCounts) <- sampleTotalCounts$variable
 #generate the total counts for each sample collection
  mcounts$TotalCounts <- sampleTotalCounts[mcounts$variable,"Counts"]
 #ratio of certain strain counts over total counts in each sample
  mcounts$RelativeCounts <- mcounts$Counts / mcounts$TotalCounts
  mcounts<-subset(mcounts, mcounts$SampleNum %in% index$SampleIndex)
  mcounts[,ncol(mcounts)+1:6] <- index[mcounts$SampleNum,
    c("LibraryName","SampleIndex","StarvingMedia","Replicate","SamplingTime","PrimerIndex")]
  datar[[MM]] <- mcounts[,c("Strain","SampleNum","Tag",
      "LibraryName","SampleIndex","StarvingMedia","Replicate","SamplingTime","PrimerIndex",
      "Counts","RelativeCounts")]
}

#A sample of what that looks like:
datar[[1]][1:5,1:10]
#select my data from the whole sequencing library mixture

#mydatar<-list()
#for (MM in names(datar)) {
#  mydatar[[MM]] <- subset(datar[[MM]],datar[[MM]]$SampleNum%in%
#  index$SampleIndex)
#}
#mydatar[[1]][1:5,1:10]

mydatar <- datar 
```

#Prelim QC analysis - which libraries are good?
#Mismatch parameter?

```{r,cache=TRUE}
#So which mismatch tolerance to use? The assumption is that some barcodes ain’t perfect, and that Barnone will find the right one within a mismatch parameter.
#Which one to use?
#Presumably there’s only real barcodes in the library, so I should increase the parameter to the point where I get more reads per strain, but not at the point where strains start to canabalize counts from other strains.
summedCounts <- list()
for (MM in names(mydatar)) {
  summedCounts[[MM]] <- aggregate(Counts~Strain+Tag,FUN=sum,
      data=subset(mydatar[[MM]], Replicate!=""))
}
allSummedCounts <- data.table::rbindlist(summedCounts,idcol=T)
dallSummedCounts <- dcast(data=allSummedCounts,Strain+Tag~.id,value.var="Counts")

g <- ggplot(dallSummedCounts)+
  facet_wrap(~Tag)+
  scale_y_log10()+scale_x_log10()+theme_bw()+
  geom_point(size=0.1)
g+aes(x=`0MM`,y=`1MM`)
g+aes(x=`1MM`,y=`2MM`)

dallSummedCounts_m<-melt(dallSummedCounts, id.var=c("Strain","Tag"))

ggplot(dallSummedCounts_m)+aes(x=value,col=variable)+
  theme_bw()+scale_x_log10()+
  ylab("Strain counts distribution")+
  stat_bin(position="identity",geom="line",bins=200)+
  facet_grid(variable~Tag)





#saving files
for (MM in names(mydatar)) {
  write.csv(file=paste0("../tmp/N_lim4",MM,"Melted.csv"),
    x=subset(mydatar[[MM]],Replicate!=""))
}
for (MM in names(mydatar)) {
  write.csv(file=paste0("../tmp/N_lim4",MM,".csv"),
    x=dcast(subset(mydatar[[MM]],Replicate!=""),#,"Starvation","SamplingIndex","Replicate","SamplingTime","BarTag"
      Strain+Tag~SampleNum+LibraryName+StarvingMedia+SampleIndex+Replicate+SamplingTime,
      value.var="Counts"))
}

```


```{r,cache=TRUE}
useMM <- "2MM"
sdat <- subset(mydatar[[useMM]])
sdat[,c(2:5,7,9)] <- lapply(sdat[,c(2:5,7,9)],factor)

ggplot(sdat)+
  aes(x=factor(SamplingTime),
    col=LibraryName:Replicate:factor(SamplingTime),weight=Counts)+
  facet_grid(Tag~Replicate+LibraryName)+geom_point(stat="count")+
  theme(axis.text.x=element_text(angle=90))+
  scale_y_log10()

ggplot(sdat)+
  aes(x=Replicate:factor(SamplingTime),y=Counts)+
  geom_boxplot()+scale_y_log10()+
  facet_wrap(~LibraryName+Tag,scales="free_x")+
  theme(axis.text.x=element_text(angle=90))

#Indexing numeric data: values will be adjusted so they are equal to each other in a given starting time period.
nozerosdat<-subset(sdat,sdat$Counts>0)
##for (i in unique(nozerosdat$Strain)){
  #    s<-subset(nozerosdat, nozerosdat$Strain==i)
  #    apply(s, 1, function(x){return x})}

```

## add up samples UP and DOWN tag

```{r}
#zeroMM<-subset(allSummedBySample, allSummedBySample$.id=="0MM")
#zeroMM_sum<-aggregate(zeroMM$Counts ~ zeroMM$SampleNum, FUN = sum)
```


### PCA analysis
```{r,fig.height=10,cache=TRUE}
#Sample_2MM<-allSummedBySample[allSummedBySample$Counts>5e4 & allSummedBySample$.id=="2MM"]
filterData<-subset(sdat)#, sdat$SampleNum %in% Sample_2MM$SampleNum)
ssdat<-subset(sdat,sdat$Counts >0 )
dsdat <- dcast(Strain~SampleNum+Tag+LibraryName+Replicate+SamplingTime+StarvingMedia,
  data=ssdat,value.var="Counts")
dsdat[is.na(dsdat)] <- 0
rownames(dsdat) <- dsdat[,1]
dsdat <- dsdat[,-1]

upc <- prcomp(t(dsdat[,grepl("UP",names(dsdat))]),center=T,scale.=F)
upz <- data.frame(upc$x)
upz[,ncol(upz)+(1:6)] <- colsplit(rownames(upz),"_",
  names=c("SampleNum","Tag","LibraryName","Replicate","SamplingTime","StarvingMedia"))
upz[ncol(upz)-(0:5)] <- lapply(upz[ncol(upz)-(0:5)],factor)

dpc <- prcomp(t(dsdat[,grepl("DOWN",names(dsdat))]),center=T,scale.=F)
dpz <- data.frame(dpc$x)
dpz[,ncol(dpz)+(1:6)] <- colsplit(rownames(dpz),"_",
  names=c("SampleNum","Tag","LibraryName","Replicate","SamplingTime","StarvingMedia"))
dpz[ncol(dpz)-(0:5)] <- lapply(dpz[ncol(dpz)-(0:5)],factor)

######Plot PCA vs UP and DN tag
g <- ggplot(pz)+geom_point()+theme(legend.position="bottom")
g+aes(x=PC1,PC2)

g+facet_wrap(~Tag+Replicate,scales="free")+
  aes(x=PC1,y=PC2,col=LibraryName:SamplingTime)

g+facet_wrap(~Tag+LibraryName,scales="free")+
  aes(x=PC1,y=PC2,col=SamplingTime:Replicate)

###

gu <- ggplot(upz)+geom_point()+theme(legend.position="bottom")
gu+facet_wrap(~Tag+Replicate,scales="free")+
  aes(x=PC1,y=PC2,col=LibraryName:SamplingTime)

gd <- ggplot(dpz)+geom_point()+theme(legend.position="bottom")
gd+facet_wrap(~Tag+Replicate,scales="free")+
  aes(x=PC1,y=PC2,col=LibraryName:SamplingTime)

########Plot PCA seperated by tag and library
g <- ggplot(pz)+
  geom_point()+theme(legend.position="bottom")

g+facet_wrap(~Tag,scales="free")+
  aes(x=PC1,y=PC2,col=LibraryName:SamplingTime:Replicate)+
  geom_text_repel(aes(label=LibraryName),alpha=0.5,nudge_x=200)

g+facet_wrap(~LibraryName+Tag,scales="free")+
  aes(x=PC1,y=PC2,col=LibraryName:SamplingTime:Replicate)+
  geom_text_repel(aes(label=LibraryName),alpha=0.5,nudge_x=200)

########Plot PCA seperated by sampling time
g <- ggplot(pz)+
  geom_point()+theme(legend.position="bottom")

g+facet_grid(Tag~SamplingTime,scales="free")+
      aes(x=PC1,y=PC2,col=Replicate)+
      geom_text_repel(aes(label=LibraryName),size=3,alpha=0.5,nudge_y=200)

#g+facet_wrap(Tag~LibraryName+SamplingTime,scales="free")+
  

#plot for PC3vsPC4 -- the less representative components for the data set
g+facet_wrap(~Tag,scales="free")+
  aes(x=PC3,y=PC4,col=LibraryName:SamplingTime:Replicate)+
  geom_text_repel(aes(label=LibraryName),alpha=0.5,nudge_x=200)
g+facet_wrap(~LibraryName+Tag,scales="free")+
  aes(x=PC3,y=PC4,col=LibraryName:SamplingTime:Replicate)+
  geom_text_repel(aes(label=LibraryName),alpha=0.5,nudge_x=200)
```

```{r}
#ggplot(mydatar)+theme_bw()+aes(x=(sumz))+
#    geom_histogram(binwidth=50)+facet_grid(time~pulse+replicate)+
#    xlim(0,4e3)
```




